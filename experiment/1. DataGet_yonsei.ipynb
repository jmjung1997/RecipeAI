{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연세대 세브란스에서 건강정보에 대한 식단 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import re\n",
    "\n",
    "url1 = 'https://sev.severance.healthcare/health/lifecare/nutrition/diseasediet.do?&mode=view&articleNo=108731&articleLimit=0'\n",
    "url2 = 'https://sev.severance.healthcare/health/lifecare/nutrition/diseasediet.do?&mode=view&articleNo=70483&articleLimit=0'\n",
    "\n",
    "def clean_text(element):\n",
    "   text = element.get_text().strip()\n",
    "   text = re.sub(r'\\s+', ' ', text)\n",
    "   return text\n",
    "\n",
    "class CustomWebLoader(WebBaseLoader):\n",
    "   def _clean_data(self, soup: bs4.BeautifulSoup) -> str:\n",
    "       # 자바스크립트 태그 제거\n",
    "       [s.decompose() for s in soup.find_all('script')]\n",
    "       \n",
    "       subject = soup.find('h3', class_='subject')\n",
    "       title = clean_text(subject) if subject else \"\"\n",
    "       \n",
    "       fr_view = soup.find('div', class_='fr-view')\n",
    "       if fr_view:\n",
    "           paragraphs = [p for p in fr_view.find_all('p', recursive=False) \n",
    "                        if clean_text(p) and not p.find('img')]\n",
    "           content = ' '.join(clean_text(p) for p in paragraphs)\n",
    "           return f\"제목: {title}\\n\\n본문:\\n{content}\"\n",
    "       return \"\"\n",
    "\n",
    "loader = CustomWebLoader(web_path=(url1, url2))\n",
    "docs = loader.load()\n",
    "\n",
    "with open('C:\\jupyter\\RecipeAI\\stroke_diet.txt', 'w', encoding='utf-8') as f:\n",
    "   f.write(str(docs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautifulsoup과 selenium 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크롤링 중: 항암치료 중 식사요법 Chemotherapy\n",
      "저장 완료: crawled_data\\항암치료 중 식사요법 Chemotherapy.txt\n",
      "크롤링 중: 뇌졸중의 식사요법 Stroke\n",
      "저장 완료: crawled_data\\뇌졸중의 식사요법 Stroke.txt\n",
      "크롤링 중: 역류성 식도염의 식사요법 Reflux esophagitis\n",
      "저장 완료: crawled_data\\역류성 식도염의 식사요법 Reflux esophagitis.txt\n",
      "크롤링 중: 변비의 식사요법 Constipation\n",
      "저장 완료: crawled_data\\변비의 식사요법 Constipation.txt\n",
      "크롤링 중: 골다공증의 식사요법 Osteoporosis\n",
      "저장 완료: crawled_data\\골다공증의 식사요법 Osteoporosis.txt\n",
      "크롤링 중: 골다공증의 식사요법 2 Osteoporosis\n",
      "저장 완료: crawled_data\\골다공증의 식사요법 2 Osteoporosis.txt\n",
      "크롤링 중: 당뇨병의 식사요법 Diabetes mellitus\n",
      "저장 완료: crawled_data\\당뇨병의 식사요법 Diabetes mellitus.txt\n",
      "크롤링 중: 빈혈의 식사요법 Anemia\n",
      "저장 완료: crawled_data\\빈혈의 식사요법 Anemia.txt\n",
      "크롤링 중: 지방간의 식사요법 Fatty liver\n",
      "저장 완료: crawled_data\\지방간의 식사요법 Fatty liver.txt\n",
      "크롤링 중: 지방간의 식사요법 2 Fatty liver\n",
      "저장 완료: crawled_data\\지방간의 식사요법 2 Fatty liver.txt\n",
      "크롤링 중: 이상지질혈증의 식사요법 Dyslipidemia\n",
      "저장 완료: crawled_data\\이상지질혈증의 식사요법 Dyslipidemia.txt\n",
      "크롤링 중: 통풍의 식사요법 Gout\n",
      "저장 완료: crawled_data\\통풍의 식사요법 Gout.txt\n",
      "크롤링 중: 고혈압의 식사요법 Hypertension\n",
      "저장 완료: crawled_data\\고혈압의 식사요법 Hypertension.txt\n",
      "크롤링 중: 과민성 대장증후군의 식사요법 Irritable bowel syndrome (IBS)\n",
      "저장 완료: crawled_data\\과민성 대장증후군의 식사요법 Irritable bowel syndrome IBS.txt\n",
      "크롤링 중: 갑상선기능항진증의 식사요법 Hyperthyroidism\n",
      "저장 완료: crawled_data\\갑상선기능항진증의 식사요법 Hyperthyroidism.txt\n",
      "크롤링 중: 위-식도역류병의 식사요법 Gastro-esophageal reflux disease(GERD)\n",
      "저장 완료: crawled_data\\위-식도역류병의 식사요법 Gastro-esophageal reflux diseaseGERD.txt\n",
      "크롤링 중: 담석증의 식사요법 Cholelithiasis\n",
      "저장 완료: crawled_data\\담석증의 식사요법 Cholelithiasis.txt\n",
      "크롤링 중: 만성 콩팥병(만성 신장병)의 식사요법 Chronic renal disease\n",
      "저장 완료: crawled_data\\만성 콩팥병만성 신장병의 식사요법 Chronic renal disease.txt\n",
      "크롤링 중: 염증성장질환의 식사요법 Inflammatory bowel disease (IBD)\n",
      "저장 완료: crawled_data\\염증성장질환의 식사요법 Inflammatory bowel disease IBD.txt\n",
      "크롤링 중: 만성폐쇄성폐질환의 식사요법 Chronic obstructive pulmonary disease (COPD)\n",
      "저장 완료: crawled_data\\만성폐쇄성폐질환의 식사요법 Chronic obstructive pulmonary disease COPD.txt\n",
      "크롤링 중: 혈관성 치매의 식사요법 Vascular dementia\n",
      "저장 완료: crawled_data\\혈관성 치매의 식사요법 Vascular dementia.txt\n",
      "크롤링 중: 파킨슨병의 식사요법 Parkinson disease\n",
      "저장 완료: crawled_data\\파킨슨병의 식사요법 Parkinson disease.txt\n",
      "크롤링 중: 기능성 소화불량의 식사요법 Functional Dyspepsia\n",
      "저장 완료: crawled_data\\기능성 소화불량의 식사요법 Functional Dyspepsia.txt\n",
      "크롤링 중: 대장직장암의 식사요법 Colorectal cancer\n",
      "저장 완료: crawled_data\\대장직장암의 식사요법 Colorectal cancer.txt\n",
      "크롤링 중: 식사성 칼슘 결핍 시 식사요법 Dietary calcium deficiency\n",
      "저장 완료: crawled_data\\식사성 칼슘 결핍 시 식사요법 Dietary calcium deficiency.txt\n",
      "크롤링 중: 아토피피부염의 식사요법 Atopic dermatitis\n",
      "저장 완료: crawled_data\\아토피피부염의 식사요법 Atopic dermatitis.txt\n",
      "크롤링 중: 설사 시 식사요법 Diarrhea\n",
      "저장 완료: crawled_data\\설사 시 식사요법 Diarrhea.txt\n",
      "크롤링 중: 암 치료 중 식사요법\n",
      "저장 완료: crawled_data\\암 치료 중 식사요법.txt\n",
      "크롤링 중: 암 환자의 증상별 식사요법\n",
      "저장 완료: crawled_data\\암 환자의 증상별 식사요법.txt\n",
      "크롤링 중: 위암의 식사요법 Stomach cancer\n",
      "저장 완료: crawled_data\\위암의 식사요법 Stomach cancer.txt\n",
      "크롤링 중: 심부전의 식사요법 Heart failure\n",
      "저장 완료: crawled_data\\심부전의 식사요법 Heart failure.txt\n",
      "크롤링 중: 비만의 식사요법 Obesity\n",
      "저장 완료: crawled_data\\비만의 식사요법 Obesity.txt\n",
      "크롤링 중: 유당불내증(유당분해효소결핍증)의 식사요법 Lactose intolerance\n",
      "저장 완료: crawled_data\\유당불내증유당분해효소결핍증의 식사요법 Lactose intolerance.txt\n",
      "크롤링 중: 대사증후군의 식사요법 Metabolic syndrome\n",
      "저장 완료: crawled_data\\대사증후군의 식사요법 Metabolic syndrome.txt\n",
      "크롤링 중: 간경변증의 식사요법 Liver cirrhosis\n",
      "저장 완료: crawled_data\\간경변증의 식사요법 Liver cirrhosis.txt\n",
      "크롤링 중: 케톤 생성 식사요법 Ketogenic diet\n",
      "저장 완료: crawled_data\\케톤 생성 식사요법 Ketogenic diet.txt\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "\n",
    "class SeveranceCrawler:\n",
    "    def __init__(self):\n",
    "        # Chrome 드라이버 옵션 설정\n",
    "        self.options = webdriver.ChromeOptions()\n",
    "        self.options.add_argument('--headless')  # 헤드리스 모드\n",
    "        self.options.add_argument('--no-sandbox')\n",
    "        self.options.add_argument('--disable-dev-shm-usage')\n",
    "        \n",
    "        # 크롬 드라이버 초기화\n",
    "        self.driver = webdriver.Chrome(options=self.options)\n",
    "        self.base_url = \"https://sev.severance.healthcare/health/lifecare/nutrition/diseasediet.do\"\n",
    "        \n",
    "    def get_article_links(self):\n",
    "        \"\"\"질환별 식단 목록 페이지에서 모든 글의 링크를 수집\"\"\"\n",
    "        self.driver.get(self.base_url)\n",
    "        time.sleep(2)  # 페이지 로딩 대기\n",
    "        \n",
    "        links = []\n",
    "        try:\n",
    "            # 더보기 버튼이 있는 경우 모두 클릭\n",
    "            while True:\n",
    "                try:\n",
    "                    more_button = self.driver.find_element(By.XPATH, \"/html/body/div/article/div[2]/div/div/div[3]/div/a\")\n",
    "                    if more_button.is_displayed():\n",
    "                        more_button.click()\n",
    "                        time.sleep(1)  # 로딩 대기\n",
    "                    else:\n",
    "                        break\n",
    "                except NoSuchElementException:\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"더보기 버튼 클릭 중 에러 발생: {str(e)}\")\n",
    "                    break\n",
    "            \n",
    "            # 썸네일 아이템들 찾기\n",
    "            articles = self.driver.find_elements(By.CSS_SELECTOR, \"div.thumb-item\")\n",
    "            \n",
    "            for article in articles:\n",
    "                try:\n",
    "                    link = article.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "                    title = article.find_element(By.CSS_SELECTOR, \"strong.subject\").text\n",
    "                    links.append({\"title\": title, \"link\": link})\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"링크 수집 중 에러 발생: {str(e)}\")\n",
    "            \n",
    "        return links\n",
    "        \n",
    "    def get_article_content(self, url):\n",
    "        \"\"\"개별 글의 내용을 크롤링\"\"\"\n",
    "        try:\n",
    "            self.driver.get(url)\n",
    "            time.sleep(2)  # 페이지 로딩 대기\n",
    "            \n",
    "            # article-body 클래스를 가진 div를 찾아서 내용 추출\n",
    "            article_body = WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"div.article-body\"))\n",
    "            )\n",
    "            \n",
    "            # BeautifulSoup으로 파싱\n",
    "            soup = BeautifulSoup(article_body.get_attribute('innerHTML'), 'html.parser')\n",
    "            \n",
    "            # 텍스트 내용 추출 (HTML 태그 제거)\n",
    "            content = soup.get_text(strip=True, separator='\\n')\n",
    "            \n",
    "            return content\n",
    "            \n",
    "        except TimeoutException:\n",
    "            print(f\"페이지 로딩 시간 초과: {url}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"내용 크롤링 중 에러 발생: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def save_content(self, title, content, output_dir=\"crawled_data\"):\n",
    "        \"\"\"크롤링한 내용을 파일로 저장\"\"\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "        # 파일명에 사용할 수 없는 문자 제거\n",
    "        safe_title = \"\".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "        \n",
    "        filename = os.path.join(output_dir, f\"{safe_title}.txt\")\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"제목: {title}\\n\\n\")\n",
    "            f.write(content)\n",
    "            \n",
    "        print(f\"저장 완료: {filename}\")\n",
    "    \n",
    "    def crawl_all_articles(self):\n",
    "        \"\"\"모든 글 크롤링\"\"\"\n",
    "        links = self.get_article_links()\n",
    "        \n",
    "        for item in links:\n",
    "            try:\n",
    "                print(f\"크롤링 중: {item['title']}\")\n",
    "                content = self.get_article_content(item['link'])\n",
    "                \n",
    "                if content:\n",
    "                    self.save_content(item['title'], content)\n",
    "                \n",
    "                time.sleep(1)  # 서버 부하 방지를 위한 대기\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"글 크롤링 중 에러 발생: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"브라우저 종료\"\"\"\n",
    "        self.driver.quit()\n",
    "\n",
    "# 실행 예시\n",
    "if __name__ == \"__main__\":\n",
    "    crawler = SeveranceCrawler()\n",
    "    \n",
    "    try:\n",
    "        crawler.crawl_all_articles()\n",
    "    finally:\n",
    "        crawler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
